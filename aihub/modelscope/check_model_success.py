import re
import shutil
from jinja2 import Environment, BaseLoader, DebugUndefined
import requests,json
import os,sys

models = ['cv-aams-style-transfer-damo', 'cv-adaint-image-color-enhance-models', 'cv-canonical-body-3d-keypoints-video', 'cv-cartoon-stable-diffusion-clipart', 'cv-cartoon-stable-diffusion-design', 'cv-cartoon-stable-diffusion-flat', 'cv-cartoon-stable-diffusion-illustration', 'cv-cartoon-stable-diffusion-watercolor', 'cv-clip-it-video-summarization-language-guided-en', 'cv-convnext-base-image-classification-garbage', 'cv-convnexttiny-ocr-recognition-document-damo', 'cv-convnexttiny-ocr-recognition-general-damo', 'cv-convnexttiny-ocr-recognition-handwritten-damo', 'cv-convnexttiny-ocr-recognition-licenseplate-damo', 'cv-convnexttiny-ocr-recognition-scene-damo', 'cv-crnn-ocr-recognition-general-damo', 'cv-cspnet-image-object-detection-yolox', 'cv-cspnet-image-object-detection-yolox-nano-coco', 'cv-cspnet-video-object-detection-streamyolo', 'cv-csrnet-image-color-enhance-models', 'cv-daflow-virtual-try-on-base', 'cv-ddcolor-image-colorization', 'cv-diffusion-text-to-image-synthesis-tiny', 'cv-dla34-table-structure-recognition-cycle-centernet', 'cv-dro-resnet18-video-depth-estimation-indoor', 'cv-dut-raft-video-stabilization-base', 'cv-ecbsr-image-super-resolution-mobile', 'cv-effnetv2-video-human-matting', 'cv-f3net-product-segmentation', 'cv-fft-inpainting-lama', 'cv-flow-based-body-reshaping-damo', 'cv-gan-face-image-generation', 'cv-googlenet-pgl-video-summarization', 'cv-gpen-image-portrait-enhancement', 'cv-gpen-image-portrait-enhancement-hires', 'cv-hdformer-body-3d-keypoints-video', 'cv-hrnet-crowd-counting-dcanet', 'cv-hrnetocr-skychange', 'cv-hrnetv2w32-body-2d-keypoints-image', 'cv-hrnetw18-hand-pose-keypoints-coco-wholebody', 'cv-hrnetw48-human-wholebody-keypoint-image', 'cv-ir-face-recognition-ood-rts', 'cv-ir101-facerecognition-cfglint', 'cv-ir50-face-recognition-arcface', 'cv-manual-face-detection-mtcnn', 'cv-manual-face-detection-tinymog', 'cv-manual-face-detection-ulfd', 'cv-manual-face-liveness-flir', 'cv-manual-face-liveness-flrgb', 'cv-manual-face-liveness-flxc', 'cv-manual-face-quality-assessment-fqa', 'cv-manual-face-recognition-frfm', 'cv-manual-face-recognition-frir', 'cv-manual-facial-landmark-confidence-flcm', 'cv-maskdino-swin-l-image-instance-segmentation-coco', 'cv-mdm-motion-generation', 'cv-mobilenet-face-2d-keypoints-alignment', 'cv-mobilenet-v2-bad-image-detecting', 'cv-nafnet-image-deblur-gopro', 'cv-nafnet-image-deblur-reds', 'cv-nafnet-image-denoise-sidd', 'cv-nanodet-face-human-hand-detection', 'cv-nerf-3d-reconstruction-accelerate-damo', 'cv-newcrfs-image-depth-estimation-indoor', 'cv-nextvit-small-image-classification-dailylife-labels', 'cv-object-detection-3d-depe', 'cv-passvitb-image-reid-person-market', 'cv-pathshift-action-recognition', 'cv-quadtree-attention-image-matching-outdoor', 'cv-r2p1d-video-embedding', 'cv-r50-panoptic-segmentation-cocopan', 'cv-raft-video-frame-interpolation', 'cv-raft-video-frame-interpolation-practical', 'cv-rdevos-video-object-segmentation', 'cv-realbasicvsr-video-super-resolution-videolq', 'cv-res2net-camouflaged-detection', 'cv-res2net-salient-detection', 'cv-resnest101-animal-recognition', 'cv-resnest101-general-recognition', 'cv-resnet-carddetection-scrfd34gkps', 'cv-resnet-face-recognition-facemask', 'cv-resnet-facedetection-scrfd10gkps', 'cv-resnet-image-quality-assessment-mos-youtubeugc', 'cv-resnet-transformer-table-structure-recognition-lore', 'cv-resnet101-detection-fewshot-defrcn', 'cv-resnet101-face-detection-cvpr22papermogface', 'cv-resnet101-image-multiple-human-parsing', 'cv-resnet101-image-single-human-parsing', 'cv-resnet18-human-detection', 'cv-resnet18-license-plate-detection-damo', 'cv-resnet18-ocr-detection-db-line-level-damo', 'cv-resnet18-ocr-detection-line-level-damo', 'cv-resnet18-ocr-detection-word-level-damo', 'cv-resnet34-face-attribute-recognition-fairface', 'cv-resnet50-bert-video-scene-segmentation-movienet', 'cv-resnet50-face-detection-retinaface', 'cv-resnet50-face-reconstruction', 'cv-resnet50-image-classification-cc', 'cv-resnet50-image-quality-assessment-degradation', 'cv-resnet50-live-category', 'cv-resnet50-ocr-detection-vlpt', 'cv-resnet50-product-bag-embedding-models', 'cv-resnet50-video-category', 'cv-resnetc3d-action-detection-detection2d', 'cv-rrdb-image-super-resolution', 'cv-segformer-b0-image-semantic-segmentation-coco-stuff164k', 'cv-segformer-b1-image-semantic-segmentation-coco-stuff164k', 'cv-segformer-b2-image-semantic-segmentation-coco-stuff164k', 'cv-segformer-b3-image-semantic-segmentation-coco-stuff164k', 'cv-segformer-b4-image-semantic-segmentation-coco-stuff164k', 'cv-segformer-b5-image-semantic-segmentation-coco-stuff164k', 'cv-stable-diffusion-paint-by-example', 'cv-stable-diffusion-v2-image-inpainting-base', 'cv-swin-b-image-instance-segmentation-coco', 'cv-swin-t-referring-video-object-segmentation', 'cv-swinb-video-panoptic-segmentation-vipseg', 'cv-swinl-image-object-detection-dino', 'cv-swinl-panoptic-segmentation-cocopan', 'cv-swinl-semantic-segmentation-cocopanmerge', 'cv-tadaconv-action-recognition', 'cv-tinynas-classification', 'cv-tinynas-detection', 'cv-tinynas-head-detection-damoyolo', 'cv-tinynas-human-detection-damoyolo', 'cv-tinynas-object-detection-damoyolo', 'cv-tinynas-object-detection-damoyolo-cigarette', 'cv-tinynas-object-detection-damoyolo-facemask', 'cv-tinynas-object-detection-damoyolo-m', 'cv-tinynas-object-detection-damoyolo-phone', 'cv-tinynas-object-detection-damoyolo-safety-helmet', 'cv-tinynas-object-detection-damoyolo-t', 'cv-tinynas-object-detection-damoyolo-traffic-sign', 'cv-tinynas-uav-detection-damoyolo', 'cv-u2net-salient-detection', 'cv-uhdm-image-demoireing', 'cv-unet-image-colorization', 'cv-unet-image-face-fusion-damo', 'cv-unet-image-matting', 'cv-unet-person-image-cartoon-3d-compound-models', 'cv-unet-person-image-cartoon-artstyle-compound-models', 'cv-unet-person-image-cartoon-compound-models', 'cv-unet-person-image-cartoon-handdrawn-compound-models', 'cv-unet-person-image-cartoon-sd-design-compound-models', 'cv-unet-person-image-cartoon-sd-illustration-compound-models', 'cv-unet-person-image-cartoon-sketch-compound-models', 'cv-unet-skin-retouching', 'cv-unet-universal-matting', 'cv-unet-video-colorization', 'cv-unet-video-deinterlace', 'cv-unifuse-panorama-depth-estimation', 'cv-vgg19-facial-expression-recognition-fer', 'cv-video-inpainting', 'cv-vit-b32-retrieval-vop', 'cv-vit-b32-retrieval-vop-bias', 'cv-vit-base-image-classification-dailylife-labels', 'cv-vit-base-image-classification-imagenet-labels', 'cv-vit-object-detection-coco', 'cv-vitadapter-semantic-segmentation-cocostuff164k', 'cv-vitb-video-single-object-tracking-ostrack', 'cv-vitb-video-single-object-tracking-ostrack-l', 'cv-vitb-video-single-object-tracking-ostrack-uav-l', 'cv-vitb-video-single-object-tracking-procontext', 'cv-vitb16-classification-vision-efficient-tuning-adapter', 'cv-vitb16-classification-vision-efficient-tuning-lora', 'cv-vitb16-classification-vision-efficient-tuning-prefix', 'cv-vitb16-classification-vision-efficient-tuning-prompt', 'cv-vitb16-segmentation-shop-seg', 'cv-vitl16-segmentation-text-driven-seg', 'cv-yolopv2-image-driving-perception-bdd100k', 'cv-yolov5-video-multi-object-tracking-fairmot', 'cv-yolox-image-object-detection-auto', 'cv-yolox-pai-hand-detection', 'mgeo-backbone-chinese-base', 'mgeo-geographic-composition-analysis-chinese-base', 'mgeo-geographic-elements-tagging-chinese-base', 'mgeo-geographic-entity-alignment-chinese-base', 'mgeo-geographic-textual-similarity-rerank-chinese-base', 'mgeo-geographic-where-what-cut-chinese-base', 'mplug-image-captioning-coco-base-en', 'mplug-image-captioning-coco-base-zh', 'mplug-image-captioning-coco-large-en', 'mplug-image-text-retrieval-flickr30k-large-en', 'mplug-visual-question-answering-coco-base-zh', 'mplug-visual-question-answering-coco-large-en', 'multi-modal-chinese-stable-diffusion-v1_0', 'multi-modal-clip-vit-base-patch16-zh', 'multi-modal-clip-vit-huge-patch14-zh', 'multi-modal-clip-vit-large-patch14-336-zh', 'multi-modal-clip-vit-large-patch14-zh', 'multi-modal-clip-vtretrival-msrvtt-53', 'ofa-image-caption-coco-6b-en', 'ofa-image-caption-coco-distilled-en', 'ofa-image-caption-coco-huge-en', 'ofa-image-caption-coco-large-en', 'ofa-image-caption-meme-large-zh', 'ofa-image-caption-muge-base-zh', 'ofa-image-classification-imagenet-large-en', 'ofa-mmspeech-asr-aishell1-base-zh', 'ofa-mmspeech-asr-aishell1-large-zh', 'ofa-mmspeech-pretrain-base-zh', 'ofa-mmspeech-pretrain-large-zh', 'ofa-ocr-recognition-document-base-zh', 'ofa-ocr-recognition-general-base-zh', 'ofa-ocr-recognition-handwriting-base-zh', 'ofa-ocr-recognition-scene-base-zh', 'ofa-ocr-recognition-web-base-zh', 'ofa-pretrain-base-en', 'ofa-pretrain-base-zh', 'ofa-pretrain-huge-en', 'ofa-pretrain-large-en', 'ofa-pretrain-large-zh', 'ofa-pretrain-medium-en', 'ofa-pretrain-tiny-en', 'ofa-summarization-gigaword-large-en', 'ofa-text-classification-mnli-large-en', 'ofa-text-to-image-synthesis-coco-large-en', 'ofa-visual-entailment-snli-ve-distilled-v2-en', 'ofa-visual-entailment-snli-ve-large-en', 'ofa-visual-grounding-refcoco-distilled-en', 'ofa-visual-grounding-refcoco-large-en', 'ofa-visual-grounding-refcoco-large-zh', 'ofa-visual-question-answering-pretrain-huge-en', 'ofa-visual-question-answering-pretrain-large-en', 'punc-ct-transformer-zh-cn-common-vocab272727-pytorch', 'speech-charctc-kws-phone-xiaoyun', 'speech-charctc-kws-phone-xiaoyun-commands', 'speech-conformer-asr-nat-zh-cn-16k-aishell1-vocab4234-pytorch', 'speech-conformer-asr-nat-zh-cn-16k-aishell2-vocab5212-pytorch', 'speech-data2vec-pretrain-zh-cn-aishell2-16k-pytorch', 'speech-dfsmn-aec-psm-16k', 'speech-dfsmn-kws-char-farfield-16k-nihaomiya', 'speech-ecapa-tdnn-sv-en-voxceleb-16k', 'speech-frcrn-ans-cirm-16k', 'speech-fsmn-vad-zh-cn-16k-common-pytorch', 'speech-fsmn-vad-zh-cn-8k-common', 'speech-inverse-text-processing-fun-text-processing-itn-de', 'speech-inverse-text-processing-fun-text-processing-itn-en', 'speech-inverse-text-processing-fun-text-processing-itn-es', 'speech-inverse-text-processing-fun-text-processing-itn-fr', 'speech-inverse-text-processing-fun-text-processing-itn-id', 'speech-inverse-text-processing-fun-text-processing-itn-ja', 'speech-inverse-text-processing-fun-text-processing-itn-ko', 'speech-inverse-text-processing-fun-text-processing-itn-pt', 'speech-inverse-text-processing-fun-text-processing-itn-ru', 'speech-inverse-text-processing-fun-text-processing-itn-tl', 'speech-inverse-text-processing-fun-text-processing-itn-vi', 'speech-mossformer-separation-temporal-8k', 'speech-paraformer-asr-nat-aishell1-pytorch', 'speech-paraformer-asr-nat-zh-cn-16k-aishell1-vocab4234-pytorch', 'speech-paraformer-asr-nat-zh-cn-16k-aishell2-vocab5212-pytorch', 'speech-paraformer-asr-nat-zh-cn-16k-common-vocab3444-tensorflow1-online', 'speech-paraformer-asr-nat-zh-cn-16k-common-vocab8358-tensorflow1', 'speech-paraformer-asr-nat-zh-cn-8k-common-vocab3444-tensorflow1-online', 'speech-paraformer-asr-nat-zh-cn-8k-common-vocab8358-tensorflow1', 'speech-paraformer-large-asr-nat-zh-cn-16k-aishell1-vocab8404-pytorch', 'speech-paraformer-large-asr-nat-zh-cn-16k-aishell2-vocab8404-pytorch', 'speech-paraformer-large-asr-nat-zh-cn-16k-common-vocab8358-tensorflow1', 'speech-paraformer-large-asr-nat-zh-cn-16k-common-vocab8404-pytorch', 'speech-paraformer-large-contextual-asr-nat-zh-cn-16k-common-vocab8404', 'speech-paraformer-large-vad-punc-asr-nat-zh-cn-16k-common-vocab8404-pytorch', 'speech-paraformer-tiny-commandword-asr-nat-zh-cn-16k-vocab544-pytorch', 'speech-paraformerbert-asr-nat-zh-cn-16k-aishell1-vocab4234-pytorch', 'speech-paraformerbert-asr-nat-zh-cn-16k-aishell2-vocab5212-pytorch', 'speech-ptts-autolabel-16k', 'speech-sambert-hifigan-tts-andy-en-us-16k', 'speech-sambert-hifigan-tts-annie-en-us-16k', 'speech-sambert-hifigan-tts-en-gb-16k', 'speech-sambert-hifigan-tts-en-us-16k', 'speech-sambert-hifigan-tts-luca-en-gb-16k', 'speech-sambert-hifigan-tts-luna-en-gb-16k', 'speech-sambert-hifigan-tts-zh-cn-16k', 'speech-sambert-hifigan-tts-zhibei-emo-zh-cn-16k', 'speech-sambert-hifigan-tts-zhitian-emo-zh-cn-16k', 'speech-sambert-hifigan-tts-zhiyan-emo-zh-cn-16k', 'speech-sambert-hifigan-tts-zhizhe-emo-zh-cn-16k', 'speech-uniasr-asr-2pass-cantonese-chs-16k-common-vocab1468-tensorflow1-offline', 'speech-uniasr-asr-2pass-cantonese-chs-16k-common-vocab1468-tensorflow1-online', 'speech-uniasr-asr-2pass-cn-dialect-16k-vocab8358-tensorflow1-offline', 'speech-uniasr-asr-2pass-cn-dialect-16k-vocab8358-tensorflow1-online', 'speech-uniasr-asr-2pass-cn-en-moe-16k-vocab8358-tensorflow1-offline', 'speech-uniasr-asr-2pass-cn-en-moe-16k-vocab8358-tensorflow1-online', 'speech-uniasr-asr-2pass-en-16k-common-vocab1080-tensorflow1-offline', 'speech-uniasr-asr-2pass-en-16k-common-vocab1080-tensorflow1-online', 'speech-uniasr-asr-2pass-es-16k-common-vocab3445-tensorflow1-offline', 'speech-uniasr-asr-2pass-es-16k-common-vocab3445-tensorflow1-online', 'speech-uniasr-asr-2pass-fa-16k-common-vocab1257-pytorch-offline', 'speech-uniasr-asr-2pass-fa-16k-common-vocab1257-pytorch-online', 'speech-uniasr-asr-2pass-id-16k-common-vocab1067-tensorflow1-offline', 'speech-uniasr-asr-2pass-id-16k-common-vocab1067-tensorflow1-online', 'speech-uniasr-asr-2pass-ja-16k-common-vocab93-tensorflow1-offline', 'speech-uniasr-asr-2pass-ja-16k-common-vocab93-tensorflow1-online', 'speech-uniasr-asr-2pass-ko-16k-common-vocab6400-tensorflow1-offline', 'speech-uniasr-asr-2pass-ko-16k-common-vocab6400-tensorflow1-online', 'speech-uniasr-asr-2pass-pt-16k-common-vocab1617-tensorflow1-offline', 'speech-uniasr-asr-2pass-pt-16k-common-vocab1617-tensorflow1-online', 'speech-uniasr-asr-2pass-ru-16k-common-vocab1664-tensorflow1-offline', 'speech-uniasr-asr-2pass-ru-16k-common-vocab1664-tensorflow1-online', 'speech-uniasr-asr-2pass-vi-16k-common-vocab1001-pytorch-offline', 'speech-uniasr-asr-2pass-vi-16k-common-vocab1001-pytorch-online', 'speech-uniasr-asr-2pass-zh-cn-16k-common-vocab8358-tensorflow1-offline', 'speech-uniasr-asr-2pass-zh-cn-16k-common-vocab8358-tensorflow1-online', 'speech-uniasr-asr-2pass-zh-cn-8k-common-vocab3445-pytorch-offline', 'speech-uniasr-asr-2pass-zh-cn-8k-common-vocab3445-pytorch-online', 'speech-uniasr-asr-2pass-zh-cn-8k-common-vocab8358-tensorflow1-offline', 'speech-uniasr-asr-2pass-zh-cn-8k-common-vocab8358-tensorflow1-online', 'speech-uniasr-large-asr-2pass-zh-cn-16k-common-vocab8358-tensorflow1-offline', 'speech-xvector-sv-zh-cn-cnceleb-16k-spk3465-pytorch', 'spring-couplet-generation']

for model in models:
    src_file = '/aihub/'+model+"/*"
    shutil.copy2(src_file, '/app/')

    from app import model

    model.set_dataset()

