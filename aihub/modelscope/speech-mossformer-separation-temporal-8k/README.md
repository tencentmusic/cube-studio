
# MossFormerè¯­éŸ³åˆ†ç¦»æ¨¡å‹ä»‹ç»

æˆ‘ä»¬æ—¥å¸¸å¯èƒ½ä¼šé‡åˆ°åœ¨å˜ˆæ‚ç¯å¢ƒä¸­è¿›è¡Œè¯­è¨€äº¤æµçš„åœºæ™¯ï¼Œæ¯”å¦‚åœ¨äººå¤šçš„é¤å…é‡Œæˆ–è€…æ‹¥æŒ¤çš„äººç¾¤ä¸­ï¼ŒåŒæ—¶å­˜åœ¨ç€è®¸å¤šä¸åŒçš„è¯´è¯äººçš„å£°éŸ³ï¼Œè¿™æ—¶å¬è€…å¯èƒ½åªå¯¹ä¸€ä¸ªä¸»è¯´è¯äººçš„å£°éŸ³æ„Ÿå…´è¶£ï¼Œå…¶ä»–è¯´è¯äººçš„å£°éŸ³å½¢æˆäº†ä¸€ç§å¬è§‰å¹²æ‰°ï¼Œå¹¸è¿çš„æ˜¯ï¼Œæˆ‘ä»¬äººç±»çš„å¬è§‰ç³»ç»Ÿå…·æœ‰é€‰æ‹©æ€§è†å¬çš„åŠŸèƒ½ï¼Œå¯ä»¥åœ¨å¤šä¸ªè¯´è¯äººçš„å£°éŸ³ä¸­é€‰æ‹©æ€§çš„è†å¬è‡ªå·±æ„Ÿå…´è¶£çš„å£°éŸ³ã€‚1953å¹´ï¼ŒColin Cherryæå‡ºäº†è‘—åçš„â€é¸¡å°¾é…’ä¼šâ€é—®é¢˜ï¼Œå³åœ¨é¸¡å°¾é…’ä¼šé‚£æ ·çš„å˜ˆæ‚ç¯å¢ƒä¸­ï¼Œæˆ‘ä»¬ä¼¼ä¹ä¹Ÿèƒ½æ¯«ä¸è´¹åŠ›åœ°åœ¨å…¶ä»–äººçš„è¯´è¯å£°å’Œç¯å¢ƒå™ªå£°çš„åŒ…å›´ä¸­å¬åˆ°ä¸€ä¸ªäººçš„è¯´è¯å†…å®¹ï¼Œä¹Ÿå°±æ˜¯è¯´äººç±»å¬è§‰ç³»ç»Ÿèƒ½è½»æ˜“åœ°å°†ä¸€ä¸ªäººçš„å£°éŸ³å’Œå¦ä¸€ä¸ªäººçš„åˆ†ç¦»å¼€æ¥ã€‚è™½ç„¶äººç±»èƒ½è½»æ˜“åœ°åˆ†ç¦»äººå£°ï¼Œä½†äº‹å®è¯æ˜ï¼Œåœ¨è¿™é¡¹åŸºæœ¬ä»»åŠ¡ä¸­ï¼Œæ„å»ºä¸€ä¸ªèƒ½å¤Ÿåª²ç¾äººç±»å¬è§‰ç³»ç»Ÿçš„è‡ªåŠ¨åŒ–ç³»ç»Ÿæ˜¯å¾ˆæœ‰æŒ‘æˆ˜æ€§çš„ã€‚â€œè¯­éŸ³åˆ†ç¦»â€ï¼ˆSpeech Separationï¼‰ä¾¿æ¥æºäºâ€œé¸¡å°¾é…’ä¼šé—®é¢˜â€ï¼Œç”±äºéº¦å…‹é£é‡‡é›†çš„éŸ³é¢‘ä¿¡å·ä¸­é™¤äº†ä¸»è¯´è¯äººä¹‹å¤–ï¼Œè¿˜å¯èƒ½åŒ…æ‹¬å™ªå£°ã€å…¶ä»–äººè¯´è¯çš„å£°éŸ³ã€æ··å“ç­‰å¹²æ‰°ã€‚è¯­éŸ³åˆ†ç¦»çš„ç›®æ ‡å³æ˜¯æŠŠç›®æ ‡è¯­éŸ³ä»èƒŒæ™¯å¹²æ‰°ä¸­åˆ†ç¦»å‡ºæ¥ã€‚å…¶åº”ç”¨èŒƒå›´ä¸ä»…åŒ…æ‹¬å¬åŠ›å‡ä½“ã€ç§»åŠ¨é€šä¿¡ã€é²æ£’çš„è‡ªåŠ¨è¯­éŸ³ä»¥åŠè¯´è¯äººè¯†åˆ«ç­‰ï¼Œæœ€è¿‘ä¹Ÿè¢«å¹¿æ³›åº”ç”¨åœ¨å„ä¸ªè¯­éŸ³æ–¹å‘çš„æœºå™¨å­¦ä¹ åœºæ™¯ä¸­ã€‚

æ ¹æ®å¹²æ‰°çš„ä¸åŒï¼Œè¯­éŸ³åˆ†ç¦»ä»»åŠ¡å¯ä»¥æ˜¯å•çº¯çš„å¤šè¯´è¯äººåˆ†ç¦»ï¼Œä¹Ÿå¯ä»¥åŒ…æ‹¬å™ªå£°æ¶ˆé™¤å’Œè§£æ··å“ç­‰é™„åŠ ä»»åŠ¡ã€‚åœ¨æ²¡æœ‰å™ªå£°å’Œæ··å“çš„æƒ…å†µä¸‹ï¼Œå•çº¯çš„è¯­éŸ³åˆ†ç¦»ä»»åŠ¡å·²ç»è¢«ç ”ç©¶äº†å‡ åå¹´ï¼Œä»æœ€åˆçš„ä¼ ç»Ÿä¿¡å·å¤„ç†ç®—æ³•åˆ°æœ€è¿‘çš„æ·±åº¦å­¦ä¹ ç®—æ³•ï¼Œç®—æ³•çš„åˆ†ç¦»æ€§èƒ½æœ‰äº†æ˜æ˜¾çš„è¿›æ­¥ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç›®æ ‡æ˜¯åœ¨ç°æœ‰æ·±åº¦å­¦ä¹ ç®—æ³•çš„åŸºç¡€ä¸Šï¼Œé€šè¿‡èå…¥æ›´å…ˆè¿›çš„é—¨æ§æ³¨æ„åŠ›æœºåˆ¶å’Œå¸¦è®°å¿†çš„æ·±åº¦å·ç§¯ç½‘ç»œï¼Œä»è€Œæ›´æœ‰æ•ˆåœ°å¯¹é•¿è¯­éŸ³åºåˆ—è¿›è¡Œå»ºæ¨¡å’Œå­¦ä¹ ï¼Œå¤§å¹…æå‡æ·±åº¦å­¦ä¹ åˆ†ç¦»ç®—æ³•çš„æ€§èƒ½ã€‚

## æ¨¡å‹æè¿°

MossFormerè¯­éŸ³åˆ†ç¦»æ¨¡å‹æ˜¯åŸºäºå¸¦å·ç§¯å¢å¼ºè”åˆæ³¨æ„åŠ›(convolution-augmented joint self-attentionsï¼‰çš„é—¨æ§å•å¤´è‡ªæ³¨æ„åŠ›æœºåˆ¶çš„æ¶æ„ï¼ˆgated single-head transformer architecture ï¼‰å¼€å‘å‡ºæ¥çš„ï¼Œé€šè¿‡é‡‡ç”¨è”åˆå±€éƒ¨å’Œå…¨å±€è‡ªæ³¨æ„åŠ›æ¶æ„ï¼ŒåŒæ—¶å¯¹å±€éƒ¨æ®µæ‰§è¡Œå®Œæ•´è‡ªæ³¨æ„åŠ›è¿ç®—å’Œå¯¹å…¨å±€æ‰§è¡Œçº¿æ€§åŒ–ä½æˆæœ¬è‡ªæ³¨æ„åŠ›è¿ç®—ï¼Œæœ‰æ•ˆæå‡å½“å‰åŒè·¯å¾„ï¼ˆDual-pathï¼‰ Transformer æ¨¡å‹åœ¨è¿œç¨‹å…ƒç´ äº¤äº’å’Œå±€éƒ¨ç‰¹å¾æ¨¡å¼çš„å»ºæ¨¡èƒ½åŠ›ã€‚é™¤äº†å¼ºå¤§çš„è¿œç¨‹å»ºæ¨¡èƒ½åŠ›å¤–ï¼Œæˆ‘ä»¬è¿˜é€šè¿‡ä½¿ç”¨å·ç§¯è¿ç®—æ¥å¢å¼º MossFormer åœ¨å±€éƒ¨ä½ç½®æ¨¡å¼çš„å»ºæ¨¡èƒ½åŠ›ã€‚å› æ­¤ï¼ŒMossFormer çš„æ€§èƒ½æ˜æ˜¾ä¼˜äºä¹‹å‰çš„æ¨¡å‹ï¼Œå¹¶åœ¨ WSJ0-2/3mix å’Œ WHAM!/WHAMR! ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„ç»“æœã€‚

<div align=center>
<img width="640" src="https://modelscope.cn/api/v1/models/damo/speech_mossformer_separation_temporal_8k/repo?Revision=master&FilePath=description/model.jpg&View=true"/>
</div>
<center>å›¾1 MossFormeræ¨¡å‹æ¶æ„å›¾</center>

MossFormerç”±ä¸€ä¸ªå·ç§¯ç¼–ç å™¨-è§£ç å™¨ç»“æ„å’Œä¸€ä¸ªæ©è”½ç½‘ç»œç»„æˆã€‚ç¼–ç å™¨-è§£ç å™¨ç»“æ„è´Ÿè´£ç‰¹å¾æå–å’Œæ³¢å½¢é‡å»ºï¼Œç¼–ç å™¨è´Ÿè´£ç‰¹å¾æå–ï¼Œç”±ä¸€ç»´ (1D) å·ç§¯å±‚ (Conv1D) å’Œæ•´æµçº¿æ€§å•å…ƒ (ReLU) ç»„æˆï¼Œåè€…å°†ç¼–ç è¾“å‡ºé™åˆ¶ä¸ºéè´Ÿå€¼ã€‚è§£ç å™¨æ˜¯ä¸€ç»´è½¬ç½®å·ç§¯å±‚ï¼Œå®ƒä½¿ç”¨ä¸ç¼–ç å™¨ç›¸åŒçš„å†…æ ¸å¤§å°å’Œæ­¥å¹…ã€‚ æ©ç ç½‘ç»œæ‰§è¡Œä»ç¼–ç å™¨è¾“å‡ºåˆ°ğ¶ç»„æ©ç çš„éçº¿æ€§æ˜ å°„ï¼Œæ©ç ç½‘ç»œçš„ä¸»ç»„æˆéƒ¨åˆ†æ˜¯MossFormeræ¨¡å—ï¼Œä¸€ä¸ªMossFormer æ¨¡å—ç”±å››ä¸ªå·ç§¯æ¨¡å—ã€ç¼©æ”¾å’Œåç§»æ“ä½œã€è”åˆå±€éƒ¨å’Œå…¨å±€ å•å¤´è‡ªæ³¨æ„åŠ›ï¼ˆSHSAï¼‰ ä»¥åŠä¸‰ä¸ªé—¨æ§æ“ä½œç»„æˆï¼Œè´Ÿè´£è¿›è¡Œé•¿åºåˆ—çš„å¤„ç†ã€‚

ç†è®ºä¸Šï¼Œæˆ‘ä»¬çš„æ¨¡å‹æ¡†æ¶å¯ä»¥æ”¯æŒä»»æ„å¤šè¯´è¯äººå’Œä»»æ„ç¯å¢ƒä¸‹çš„è¯­éŸ³åˆ†ç¦»ä»»åŠ¡ï¼Œæˆ‘ä»¬åœ¨ModelScopeä¸Šé¦–å…ˆå¼€æ”¾çš„æ˜¯åŸºäºä¸¤ä¸ªè¯´è¯äººçš„çº¯è¯­éŸ³åˆ†ç¦»æ¨¡å‹ï¼Œå…¶ç›®çš„æ˜¯è®©ç”¨æˆ·å¯ä»¥åœ¨è¾ƒç®€å•çš„åˆ†ç¦»ä»»åŠ¡ä¸Šï¼Œæ›´å¿«é€Ÿçš„æ­å»ºå’Œæµ‹è¯•æˆ‘ä»¬çš„æ¨¡å‹å¹³å°ã€‚

## æ¨¡å‹çš„ä½¿ç”¨æ–¹å¼

æ¨¡å‹pipeline è¾“å…¥ä¸ºä¸ª8000Hzé‡‡æ ·ç‡çš„å•å£°é“wavæ–‡ä»¶ï¼Œå†…å®¹æ˜¯ä¸¤ä¸ªäººæ··æ‚åœ¨ä¸€èµ·çš„è¯´è¯å£°ï¼Œè¾“å‡ºç»“æœæ˜¯åˆ†ç¦»å¼€çš„ä¸¤ä¸ªå•å£°é“éŸ³é¢‘ã€‚

#### ç¯å¢ƒå‡†å¤‡

* æœ¬æ¨¡å‹æ”¯æŒLinuxï¼ŒWindowså’ŒMacOSå¹³å°ã€‚
* æœ¬æ¨¡å‹ä¾èµ–å¼€æºåº“SpeechBrainï¼Œç”±äºå®ƒå¯¹PyTorchç‰ˆæœ¬ä¾èµ–æ¯”è¾ƒè‹›åˆ»ï¼Œå› æ­¤æ²¡æœ‰åŠ å…¥ModelScopeçš„é»˜è®¤ä¾èµ–ä¸­ï¼Œéœ€è¦ç”¨æˆ·æ‰‹åŠ¨å®‰è£…ï¼š

```shell
# å¦‚æœæ‚¨çš„PyTorchç‰ˆæœ¬>=1.10 å®‰è£…æœ€æ–°ç‰ˆå³å¯
pip install speechbrain
# å¦‚æœæ‚¨çš„PyTorchç‰ˆæœ¬ <1.10 ä¸” >=1.7ï¼Œå¯ä»¥æŒ‡å®šå¦‚ä¸‹ç‰ˆæœ¬å®‰è£…
pip install speechbrain==0.5.12
```

* æœ¬æ¨¡å‹è¿˜ä½¿ç”¨äº†ä¸‰æ–¹åº“SoundFileè¿›è¡Œwavæ–‡ä»¶å¤„ç†ï¼Œ**åœ¨Linuxç³»ç»Ÿä¸Šç”¨æˆ·éœ€è¦æ‰‹åŠ¨å®‰è£…SoundFileçš„åº•å±‚ä¾èµ–åº“libsndfile**ï¼Œåœ¨Windowså’ŒMacOSä¸Šä¼šè‡ªåŠ¨å®‰è£…ä¸éœ€è¦ç”¨æˆ·æ“ä½œã€‚è¯¦ç»†ä¿¡æ¯å¯å‚è€ƒ[SoundFileå®˜ç½‘](https://github.com/bastibe/python-soundfile#installation)ã€‚ä»¥Ubuntuç³»ç»Ÿä¸ºä¾‹ï¼Œç”¨æˆ·éœ€è¦æ‰§è¡Œå¦‚ä¸‹å‘½ä»¤:

```shell
sudo apt-get update
sudo apt-get install libsndfile1
```

#### ä»£ç èŒƒä¾‹

```python
import numpy
import soundfile as sf
from modelscope.pipelines import pipeline
from modelscope.utils.constant import Tasks

# inputå¯ä»¥æ˜¯urlä¹Ÿå¯ä»¥æ˜¯æœ¬åœ°æ–‡ä»¶è·¯å¾„
input = 'https://modelscope.cn/api/v1/models/damo/speech_mossformer_separation_temporal_8k/repo?Revision=master&FilePath=examples/mix_speech1.wav'
separation = pipeline(
   Tasks.speech_separation,
   model='damo/speech_mossformer_separation_temporal_8k')
result = separation(input)
for i, signal in enumerate(result['output_pcm_list']):
    save_file = f'output_spk{i}.wav'
    sf.write(save_file, numpy.frombuffer(signal, dtype=numpy.int16), 8000)
```

#### æ¨¡å‹å±€é™æ€§

æœ¬æ¨¡å‹ä»…åœ¨çº¯è¯­éŸ³æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒå®Œæˆçš„ï¼Œå› è€Œæ— æ³•ä¿éšœåœ¨å¸¦æ··å“å’Œå™ªå£°æƒ…å†µä¸‹çš„åˆ†ç¦»æ•ˆæœï¼Œæˆ‘ä»¬åç»­ä¼šè¿›ä¸€æ­¥å‘å¸ƒå¯ä»¥åŒæ—¶å¤„ç†å¸¦æ··å“å’Œå™ªå£°çš„è¯­éŸ³åˆ†ç¦»æ¨¡å‹ï¼Œæ•¬è¯·æœŸå¾…ï¼

## è®­ç»ƒæ•°æ®ä»‹ç»
é­”æ­ç¤¾åŒºä¸Šå¼€æ”¾çš„æ¨¡å‹ä½¿ç”¨çº¦30å°æ—¶2äººæ··åˆè¯­éŸ³ä½œä¸ºè®­ç»ƒæ•°æ®ã€‚æ··åˆè¯­éŸ³æ˜¯åŸºäºWSJ0æ•°æ®é›†ç”Ÿæˆçš„ï¼Œç”±äºWSJ0çš„Licenseé—®é¢˜æ— æ³•åœ¨è¿™é‡Œåˆ†äº«ã€‚æˆ‘ä»¬åœ¨ModelScopeä¸Šæä¾›äº†åŸºäºLibriSpeechæ•°æ®é›†ç”Ÿæˆçš„æ··åˆéŸ³é¢‘ï¼Œä»¥ä¾¿æ‚¨å¿«é€Ÿå¼€å§‹è®­ç»ƒã€‚å…¶ä¸­è®­ç»ƒé›†åŒ…å«çº¦42å°æ—¶è¯­éŸ³ï¼Œå…±13900æ¡ï¼Œå¤§å°çº¦7Gã€‚

## æ¨¡å‹è®­ç»ƒ
### ç¯å¢ƒå‡†å¤‡
ModelScopeç½‘ç«™å®˜æ–¹æä¾›çš„Notebookç¯å¢ƒå·²ç»å®‰è£…å¥½äº†æ‰€æœ‰ä¾èµ–ï¼Œèƒ½å¤Ÿç›´æ¥å¼€å§‹è®­ç»ƒã€‚å¦‚æœæ‚¨è¦åœ¨è‡ªå·±çš„è®¾å¤‡ä¸Šè®­ç»ƒï¼Œå¯ä»¥å‚è€ƒä¸Šä¸€èŠ‚çš„ç¯å¢ƒå‡†å¤‡æ­¥éª¤ã€‚ç¯å¢ƒå‡†å¤‡å®Œæˆåå»ºè®®è¿è¡Œæ¨ç†ç¤ºä¾‹ä»£ç ï¼ŒéªŒè¯æ¨¡å‹å¯ä»¥æ­£å¸¸å·¥ä½œã€‚

### è®­ç»ƒæ­¥éª¤
ä»¥ä¸‹åˆ—å‡ºçš„ä¸ºè®­ç»ƒç¤ºä¾‹ä»£ç ï¼Œå…¶ä¸­work_dirå¯ä»¥æ›¿æ¢æˆæ‚¨éœ€è¦çš„è·¯å¾„ã€‚è®­ç»ƒlogä¼šä¿å­˜åœ¨work_dir/log.txtï¼Œè®­ç»ƒä¸­çš„æ¨¡å‹å‚æ•°ç­‰æ•°æ®ä¼šä¿å­˜åœ¨work_dir/save/CKPT+timestampè·¯å¾„ä¸‹ã€‚æ•°æ®è®­ç»ƒä¸€éä¸ºä¸€ä¸ªepochï¼Œé»˜è®¤å…±è®­ç»ƒ120ä¸ªepochï¼Œåœ¨ç¡¬ä»¶é…ç½®ä¸º20æ ¸ CPU å’ŒV100 GPU çš„æœºå™¨ä¸Šéœ€è¦çº¦10å¤©ã€‚

```python
import os

from datasets import load_dataset

from modelscope.metainfo import Trainers
from modelscope.msdatasets import MsDataset
from modelscope.preprocessors.audio import AudioBrainPreprocessor
from modelscope.trainers import build_trainer
from modelscope.utils.audio.audio_utils import to_segment

work_dir = './train_dir'
if not os.path.exists(work_dir):
    os.makedirs(work_dir)

train_dataset = MsDataset.load(
        'Libri2Mix_8k', split='train').to_torch_dataset(preprocessors=[
        AudioBrainPreprocessor(takes='mix_wav:FILE', provides='mix_sig'),
        AudioBrainPreprocessor(takes='s1_wav:FILE', provides='s1_sig'),
        AudioBrainPreprocessor(takes='s2_wav:FILE', provides='s2_sig')
    ],
    to_tensor=False)
eval_dataset = MsDataset.load(
        'Libri2Mix_8k', split='validation').to_torch_dataset(preprocessors=[
        AudioBrainPreprocessor(takes='mix_wav:FILE', provides='mix_sig'),
        AudioBrainPreprocessor(takes='s1_wav:FILE', provides='s1_sig'),
        AudioBrainPreprocessor(takes='s2_wav:FILE', provides='s2_sig')
    ],
    to_tensor=False)
kwargs = dict(
    model='damo/speech_mossformer_separation_temporal_8k',
    train_dataset=train_dataset,
    eval_dataset=eval_dataset,
    work_dir=work_dir)
trainer = build_trainer(
    Trainers.speech_separation, default_args=kwargs)
trainer.train()
```

## æ•°æ®è¯„ä¼°åŠç»“æœ

ä»¥ä¸‹åˆ—å‡ºçš„ä¸ºæ¨¡å‹è¯„ä¼°ä»£ç ï¼Œå…¶ä¸­work_diræ˜¯å·¥ä½œè·¯å¾„ï¼Œè¦è¯„ä¼°çš„æ¨¡å‹å¿…é¡»æ”¾åœ¨work_dir/save/CKPT+timestampè·¯å¾„ä¸‹ï¼Œç¨‹åºä¼šæœç´¢è·¯å¾„ä¸‹çš„æœ€ä½³æ¨¡å‹å¹¶è‡ªåŠ¨åŠ è½½ã€‚

```python
import os

from datasets import load_dataset

from modelscope.metainfo import Trainers
from modelscope.msdatasets import MsDataset
from modelscope.preprocessors.audio import AudioBrainPreprocessor
from modelscope.trainers import build_trainer
from modelscope.utils.audio.audio_utils import to_segment

work_dir = './train_dir'
if not os.path.exists(work_dir):
    os.makedirs(work_dir)

train_dataset = None
eval_dataset = MsDataset.load(
        'Libri2Mix_8k', split='test').to_torch_dataset(preprocessors=[
        AudioBrainPreprocessor(takes='mix_wav:FILE', provides='mix_sig'),
        AudioBrainPreprocessor(takes='s1_wav:FILE', provides='s1_sig'),
        AudioBrainPreprocessor(takes='s2_wav:FILE', provides='s2_sig')
    ],
    to_tensor=False)
kwargs = dict(
    model='damo/speech_mossformer_separation_temporal_8k',
    train_dataset=train_dataset,
    eval_dataset=eval_dataset,
    work_dir=work_dir)
trainer = build_trainer(
    Trainers.speech_separation, default_args=kwargs)
trainer.model.load_check_point(device=trainer.device)
print(trainer.evaluate(None))
```

MossFormeræ¨¡å‹ä¸å…¶å®ƒSOTAæ¨¡å‹åœ¨å…¬å¼€æ•°æ®é›†WSJ0-2mix/3mixå’ŒWHAMï¼/WHAMRï¼ä¸Šçš„å¯¹æ¯”ç»“æœå¦‚ä¸‹ï¼š

<div align=center>
<img width="640" src="https://modelscope.cn/api/v1/models/damo/speech_mossformer_separation_temporal_8k/repo?Revision=master&FilePath=description/matrix.jpg&View=true"/>
</div>
<center>å›¾2 å„æ¨¡å‹è¯„ä¼°ç»“æœ</center>

### æŒ‡æ ‡è¯´æ˜ï¼š

* SI-SNR (Scale Invariant Signal-to-Noise Ratio) å°ºåº¦ä¸å˜çš„ä¿¡å™ªæ¯”ï¼Œæ˜¯åœ¨æ™®é€šä¿¡å™ªæ¯”åŸºç¡€ä¸Šé€šè¿‡æ­£åˆ™åŒ–æ¶ˆå‡ä¿¡å·å˜åŒ–å¯¼è‡´çš„å½±å“ï¼Œæ˜¯é’ˆå¯¹å®½å¸¦å™ªå£°å¤±çœŸçš„è¯­éŸ³å¢å¼ºç®—æ³•çš„å¸¸è§„è¡¡é‡æ–¹æ³•ã€‚SI-SNRi (SI-SNR improvement) æ˜¯è¡¡é‡å¯¹æ¯”åŸå§‹æ··åˆè¯­éŸ³ï¼ŒSI-SNRåœ¨åˆ†ç¦»åè¯­éŸ³ä¸Šçš„æå‡é‡ã€‚
* DM (Dynamic Mixing)æ˜¯ä¸€ç§åŠ¨æ€æ··åˆæ•°æ®å¢å¼ºç®—æ³•ï¼Œç”¨æ¥è¡¥å……è®­ç»ƒæ•°æ®çš„ä¸è¶³å’Œæå‡æ¨¡å‹è®­ç»ƒçš„æ³›åŒ–èƒ½åŠ›ã€‚

#### ç›¸å…³è®ºæ–‡ä»¥åŠå¼•ç”¨ä¿¡æ¯

Zhao, Shengkui and Ma, Bin, â€œMossFormer: Pushing the Performance Limit of Monaural Speech Separation using Gated Single-head Transformer with Convolution-augmented Joint Self-Attentionsâ€, Accepted by ICASSP 2023.

```BibTeX

```
